# Idiocratic Much?

After writing about [how companies get distracted by competitive dynamic](https://github.com/k1monfared/notes/blob/main/blog/20250913_foundation_or_competition.md), I got some great feedback that helped me clarify some of my thoughts.

## Am I Cherry-Picking Examples?

Yes, absolutely. Statistically speaking, shiny things win more often than fundamental solutions. That's exactly the problem I'm trying to highlight.

The fact that flashy, immediately impressive solutions usually win isn't evidence that markets work well - it's evidence of a systematic bias that markets amplify. My examples of Google, Signal, and AWS are noteworthy precisely because they're exceptions to the rule. Most companies that ignored competitive pressure and focused on boring fundamentals actually failed.

This creates a selection pressure that pushes everyone toward optimization for perception rather than reality. It's like the [rat experiments](https://skeptics.stackexchange.com/questions/43198/will-rats-given-the-ability-to-artificially-stimulate-their-pleasure-centers-sta#43213) where rats stimulate their pleasure centers until they die - except now the pleasure center adjusts its voltage to keep us alive but never satisfied. We end up with an economy optimized for engagement and short-term metrics rather than genuine human flourishing.

## Apple and Meta - Aren't They Successful?

Apple and Meta and alike represent where our society is failing itself. They might have solved some real problems at some pointÙˆ but that's not why they have "remained" successful with market measures. They're the rat side of us humans that keeps pressing the electric shock button. The unfortunate thing? They're not helpless buttons - they adjust the amount of shock so we don't die but keep pressing.

These companies have perfected the art of exploiting human psychological vulnerabilities. They're not successful because they solve fundamental human problems well, they're successful because they've industrialized addiction. The market systematically rewards companies that are better at exploiting human weaknesses rather than serving human flourishing.

When people point to "revealed preferences - people love their iPhones!" that's exactly like saying the rats "loved" pressing the pleasure button. The behavior doesn't indicate genuine well-being.

## Do Individuals Really Behave Like Companies?

The power dynamics are completely different, but individuals absolutely do optimize strategically, just like companies do. Look at someone's dating profile or Instagram page. These are carefully curated performances designed to give signals they think will win. Someone posting gym selfies even though they hate working out is doing exactly what Yahoo did with their feature-packed portal: optimizing for what they think the market wants rather than authentically representing what they actually offer.

The tragedy is that this creates competitive pressure on everyone else. Once enough people are posting adventure photos, everyone feels pressure to do the same or risk looking boring. Just like once competitors start adding AI features, every company feels they need AI features.

Even worse is when the individual doesn't actually have hobbies, so they pretend to have hobbies. Or when companies don't have real problems they're solving, so they invent problems. Apple's touch interface is a perfect example - people didn't "need" touch, it didn't solve real problems, just made things more immediately impressive. But in winning, it killed off digitizer pen technology that was actually superior for precision work. We lost decades of potential development in tools that could have been genuinely transformative for artists and designers.

## Generalists vs Specialists, or Snake Oil vs Fishermen?

A friend mentioned they see some of my examples as generalist vs specialist strategies - some companies cast a wide net, others go deep on specific problems. That's one way to look at it, but I see it more like snake oil sellers vs fishermen.

The distinction isn't really about breadth vs depth. It's about intent. Yahoo's portal strategy wasn't "generalist" in a neutral sense - they were trying to be everything to everyone to maximize attention and ad revenue. Google's search focus wasn't just "specialist" - they were actually solving a fundamental information problem that people genuinely needed solved.

In healthcare, there's real cooperation between generalists and specialists. My general practitioner constantly refers me to specialists, and when I need something from a specialist that's not their expertise, they send me back to my general doctor or to another specialist. There's an ethical framework where the professional's job is to get you the best care, even if that means losing you as a patient to someone else.

But Apple wants to be your phone, your computer, your watch, your music, your movies, your payments, your identity verification, your fitness tracker, your car interface. They're not trying to solve the phone problem really well and then refer you to the best music service - they want to own every touchpoint in your digital life. They don't just want to be the hospital, they want to be the entire city.

The difference is between "I want to be the best at solving this specific problem for you" versus "I want you to never need to go anywhere else." One is about serving you, the other is about capturing you.

## Don't Markets Self-Correct in the Long Term?

I think the market doesn't "correct" itself toward better human outcomes. It responds in whatever direction seems more profitable in the short term, but it's essentially running a greedy algorithm that looks maybe 2-3 steps ahead instead of finding globally optimal solutions. So, it's slightly better than the most naive greedy algorithm, but it's still miles from an optimal solution. (And no, I don't think the greedy in this problem approximates the optimal, by any reasonable measures.)

But here's the deeper problem: we're actively changing what the market responds to. Traditional economic theory assumes people have stable preferences and markets respond to those preferences. But we're training ourselves to only seek immediate pleasure and convenience, regardless of long-term consequences. We're creating an addicted economy where the market doesn't respond to "good" products anymore - it only responds to whatever triggers our dopamine systems most effectively.

This creates a vicious feedback loop. Our degraded preferences lead companies to build more addictive, manipulative products. These products further degrade our ability to recognize genuine value. Which leads us to reward even more sophisticated manipulation techniques. We're not just getting worse products - we're actively getting worse at wanting better products.

The smartphone addiction example illustrates this perfectly. Each incremental step toward more engaging, more addictive design increases short-term profits and user engagement. The market "corrects" toward more sophisticated manipulation techniques. But we're not just victims of this, we're active participants. We reward the companies that give us the most immediate gratification, even when we know it's bad for us. And each time we do, we get a little worse at resisting the next manipulation.

It's like we're halfway to [Idiocracy](https://www.imdb.com/title/tt0387808/), or even past it, where the market responds perfectly to what people want, but what people want has been systematically degraded to the lowest common denominator. Brawndo has electrolytes because that's what plants crave, and everyone's forgotten what plants actually need. We're training the market to give us digital Brawndo while forgetting what human flourishing actually requires.

## But Some Places Got It Right?

An economist friend pointed out something interesting about my Nordic countries example. These countries actually implemented some of the most intense economic liberalization policies in Europe and rank highly on economic freedom indices. They weren't anti-market holdouts like I might have suggested.

But this actually makes the example even better. The Nordic countries were selective about which competitive pressures to respond to and which to resist. They liberalized markets where competition seemed to serve genuine efficiency, but they didn't abandon their foundational commitments to education, healthcare, and social safety nets just because other countries were cutting those things.

They didn't get swept up in wholesale "liberalization is good" thinking. They made conscious choices about which signals from the competitive environment to follow and which to ignore, based on deeper principles about what they were actually trying to achieve for their people. Denmark might have deregulated telecommunications, but they didn't gut their education system just because it was fashionable elsewhere.

This is exactly the kind of selective resistance I'm talking about. They weren't anti-competitive - they were thoughtful about which competitions were worth engaging in and which were distractions from fundamental goals.

Market optimization and human flourishing optimization are fundamentally different problems. The market solves for revealed preferences and profit maximization. But revealed preferences in a world of engineered addiction and manufactured desires don't point toward genuine human welfare. Worse, we're actively making ourselves worse at recognizing genuine value.

This connects to a deeper issue about [what we measure and optimize for](https://github.com/k1monfared/notes/blob/main/blog/20250902_we_must_know_we_will_know.md). Just like institutions use GPA as a proxy for intelligence and then forget it's just a proxy, markets use purchasing decisions as a proxy for consumer welfare and forget they're just proxies. We end up optimizing for the measurement instead of the thing we actually care about.

The problem isn't just that these proxies are imperfect - it's that optimizing for the proxy actively distorts the underlying reality. When companies optimize for engagement metrics, they don't just fail to create genuine value - they actively destroy our capacity for sustained attention and deep satisfaction. When we optimize for looking successful on social media, we don't just fail to build authentic relationships - we actively undermine our ability to connect genuinely with others.

We've created systems where the easy thing to measure (clicks, time spent, purchases made) becomes what gets optimized for, even when it's fundamentally at odds with what we actually want (meaningful experiences, genuine connections, tools that serve our real needs).

## So What's the Solution?

To be honest, I have no clue. But, we as end users have a responsibility to give better signals to an economy that uses whatever signals it can measure. It's unfortunately a new burden on our shoulders.

I don't buy Apple products. I try not to buy big company products (though it's extremely difficult). But this isn't "convenient" for most people, who give up everything including their privacy for a bit more convenience. The energy required to constantly swim against these systems is enormous.

Most movements to "raise awareness" about these issues become temporary hypes that eventually get co-opted or fade away. Even "digital wellness" has been turned into apps and products to sell back to us. We're now entrusting the very companies that got us addicted to help us manage our addiction, but not cure it, just manage it enough so we can keep our jobs and keep paying for the substance.

The real problem isn't that people are making bad choices, but that we've structured the environment so that the easy, default choices serve corporate interests rather than human flourishing. The shiny solutions don't just win - they actively kill off non-shiny alternatives, even when those alternatives are technically superior. We're not just failing to recognize revolutionary ideas when they emerge; we've created a system that makes it nearly impossible for them to survive long enough to prove their worth.

I don't think there's an easy answer to this, or any answer at all. But recognizing that markets optimize for the wrong things, and that this optimization actively crowds out better solutions, is the first step toward understanding why we end up with a world full of addictive products instead of genuinely useful tools.